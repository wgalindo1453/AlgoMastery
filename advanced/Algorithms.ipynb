{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa0MPjmKV1p1SwqGbUDk4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wgalindo1453/AlgoMastery/blob/main/Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Greedy Algorithm\n",
        "\n",
        "A **greedy algorithm** is a simple, intuitive algorithm that is used in optimization problems. The algorithm makes the optimal choice at each step as it attempts to find the overall optimal way to solve the entire problem. Greedy algorithms have two main characteristics:\n",
        "\n",
        "1. **Locally Optimal Choices**: At each step, a greedy algorithm makes the local choice that seems best at the moment, without worrying about the consequences.\n",
        "2. **No Backtracking**: A greedy algorithm never goes back to change its choices. This can be a limitation, because it can get stuck in suboptimal solutions.\n"
      ],
      "metadata": {
        "id": "YYRylnRXkepI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Coin Change Problem\n",
        "\n",
        "Now let's see an example of a greedy algorithm. We'll implement the coin change problem, where we aim to find the minimum number of coins required to make a given amount.\n",
        "\n"
      ],
      "metadata": {
        "id": "eHJ-SEPvkn53"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_UrBCt2jqd9"
      },
      "outputs": [],
      "source": [
        "def coin_change(coins, amount):\n",
        "    # Start from largest coin and work our way down\n",
        "    coins.sort(reverse=True)\n",
        "    num_coins = 0\n",
        "    for coin in coins:\n",
        "        # Find out how many of current coin can be used without exceeding amount\n",
        "        count = amount // coin\n",
        "        num_coins += count\n",
        "        # Reduce the remaining amount\n",
        "        amount -= count * coin\n",
        "        # If no remaining amount, we're done\n",
        "        if amount == 0:\n",
        "            break\n",
        "    # If amount is not zero here, it means no solution exists\n",
        "    if amount != 0:\n",
        "        return -1\n",
        "    return num_coins\n",
        "\n",
        "coins = [1, 5, 10]\n",
        "amount = 27\n",
        "print(coin_change(coins, amount))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will give us the minimum number of coins required to make the amount 27. Remember, greedy algorithms don't always give the optimal solution for every problem, but in this case, it does. They're a simple way to get a solution quickly when the problem allows it."
      ],
      "metadata": {
        "id": "nsjh2vbtkvqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0/1 Knapsack Problem\n",
        "\n",
        "The knapsack problem is a problem in combinatorial optimization. Given a set of items, each with a weight and a value, we must determine the maximum value we can accumulate in a knapsack without exceeding its weight capacity.\n",
        "\n",
        "In the 0/1 Knapsack problem, you can't break items, so you either take the whole item or don't take it (0-1 property).\n",
        "\n",
        "## Greedy Approach to the Knapsack Problem\n",
        "\n",
        "A simple approach to solve the knapsack problem is to prioritize items with the maximum value to weight ratio. This is a greedy algorithm because it always takes the item with the best value to weight ratio without considering the implications on future choices. Note that this greedy strategy doesn't always produce an optimal solution for the 0/1 Knapsack problem, but it does work well for the Fractional Knapsack problem where you can take fractions of items.\n",
        "\n",
        "Here's a Python implementation of the greedy algorithm for the knapsack problem:\n"
      ],
      "metadata": {
        "id": "Z1540-ojlbas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knapSack(W, wt, val, n):\n",
        "    # List to store ratio of value to weight, item index\n",
        "    ratio = [(val[i]/wt[i], i) for i in range(n)]\n",
        "    # Sort the ratio list in descending order\n",
        "    ratio.sort(reverse=True)\n",
        "    \n",
        "    totalValue = 0\n",
        "    for i in range(n):\n",
        "        # If item can be fully included\n",
        "        if W >= wt[ratio[i][1]]:\n",
        "            W -= wt[ratio[i][1]]\n",
        "            totalValue += val[ratio[i][1]]\n",
        "        else:  # Item can't be fully included but add the fraction of it\n",
        "            totalValue += val[ratio[i][1]] * (W/wt[ratio[i][1]])\n",
        "            break\n",
        "    return totalValue\n",
        "\n",
        "val = [60, 100, 120]\n",
        "wt = [10, 20, 30]\n",
        "W = 50\n",
        "n = len(val)\n",
        "\n",
        "print(knapSack(W, wt, val, n))"
      ],
      "metadata": {
        "id": "o7RzQhpLlfrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will give the maximum value that can be included in the knapsack with capacity W. Remember, this approach is a greedy method and doesn't always guarantee the optimal solution for the 0/1 knapsack problem. For a guaranteed optimal solution, a dynamic programming approach would be more suitable."
      ],
      "metadata": {
        "id": "3I7t6EEqlrdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Traveling Salesman Problem (TSP)\n",
        "TSP is a classic algorithmic problem in the field of computer science and operations research. It focuses on optimization. In this problem, a salesman is given a list of cities, and must determine the shortest route that allows him to visit each city once and return to his original location.\n",
        "\n",
        "Please note that the problem is NP-Hard, so there's no known algorithm that can solve all instances of the problem efficiently (i.e., in polynomial time). Therefore, many heuristic methods, including greedy algorithms, are often used to generate reasonably good, but not necessarily optimal solutions.\n",
        "\n",
        "The simplest greedy algorithm for TSP is to always visit the nearest city next. Here's a simple Python implementation of this idea:"
      ],
      "metadata": {
        "id": "OYgFhLVuooQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traveling Salesman Problem (TSP)\n",
        "\n",
        "The Traveling Salesman Problem (TSP) is a classic algorithmic problem that focuses on optimization. A salesman is given a list of cities and must determine the shortest route that allows him to visit each city once and return to his original location.\n",
        "\n",
        "## Greedy Approach to TSP\n",
        "\n",
        "Here's a Python implementation of a greedy approach for the TSP. This approach always selects the nearest city next:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def create_data_model():\n",
        "    # Create a dictionary to represent the problem\n",
        "    data = {}\n",
        "    data['distance_matrix'] = [\n",
        "        [0, 2, 9, 10],\n",
        "        [1, 0, 6, 4],\n",
        "        [15, 7, 0, 8],\n",
        "        [6, 3, 12, 0]\n",
        "    ]\n",
        "    return data\n",
        "\n",
        "def tsp_greedy(data):\n",
        "    N = len(data['distance_matrix'])\n",
        "    visited = [False for _ in range(N)]\n",
        "    \n",
        "    # Start from node 0\n",
        "    path = [0]\n",
        "    visited[0] = True\n",
        "    \n",
        "    num_visited = 1\n",
        "    while num_visited < N:\n",
        "        last_node = path[-1]\n",
        "        next_node = np.argmin([distance if not visited[i] else np.inf for i, distance in enumerate(data['distance_matrix'][last_node])])\n",
        "        path.append(next_node)\n",
        "        visited[next_node] = True\n",
        "        num_visited += 1\n",
        "    path.append(0) # Return to start\n",
        "    \n",
        "    return path\n",
        "\n",
        "data = create_data_model()\n",
        "solution = tsp_greedy(data)\n",
        "print('Route:', solution)\n"
      ],
      "metadata": {
        "id": "aN5atnNmo0cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dynamic programming\n",
        "Dynamic programming is a method for solving complex problems by breaking them down into simpler, overlapping subproblems, and building up solutions to each of these subproblems. The idea is that if we've solved a particular subproblem once, we can store the result to avoid needing to solve it again later. This is what separates dynamic programming from the standard \"divide and conquer\" approach, and it's also the feature that gives the technique its efficiency.\n",
        "\n",
        "Now, let's illustrate this with a simple example: the Fibonacci sequence. It's a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. So the sequence is 0, 1, 1, 2, 3, 5, 8, 13, and so on. Here's a simple function that calculates the nth Fibonacci number:"
      ],
      "metadata": {
        "id": "Xrwk7wqLswGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    else:\n",
        "        return fib(n-1) + fib(n-2)\n"
      ],
      "metadata": {
        "id": "YIGrnIods4aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a clear example of a function with exponential time complexity due to overlapping subproblems.\n",
        "\n",
        "To see why, consider how many computations we perform. For fib(n), we have to compute **fib(n-1) and fib(n-2)**. Each of these, in turn, requires computing two other Fibonacci numbers, and so on.\n",
        "\n",
        "We can express the total number of computations as a recurrence relation: **T(n) = T(n-1) + T(n-2)**. This might not immediately seem like an exponential time complexity, but it is. This relation is similar to the Fibonacci sequence itself, which grows exponentially. The actual time complexity is approximately O(1.618^n), where 1.618 is the golden ratio, a number often associated with the Fibonacci sequence.\n",
        "\n",
        "While this function works, it is extremely inefficient for large values of n. This is because it repeatedly recalculates the same values. For example, to calculate fib(5), it needs to calculate fib(4) and fib(3). But to calculate fib(4), it needs to calculate fib(3) and fib(2), and so on. This leads to a lot of duplicated work.\n",
        "\n"
      ],
      "metadata": {
        "id": "3SeIIIT-s8n2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a memoized version of the Fibonacci sequence algorithm can indeed be a more intuitive introduction to dynamic programming.\n",
        "\n",
        "Memoization is a technique of storing the results of expensive function calls and reusing the results when the same inputs occur again.\n",
        "\n",
        "In the case of Fibonacci, the memoized version of the algorithm can look like this:"
      ],
      "metadata": {
        "id": "FVfuFw5hvq0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TOP-DOWN APPROACH"
      ],
      "metadata": {
        "id": "VJt7IGDh8LcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(n, memo = {}):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    elif n not in memo:\n",
        "        memo[n] = fib(n-1, memo) + fib(n-2, memo)\n",
        "    return memo[n]\n"
      ],
      "metadata": {
        "id": "-ZnGTll3vtaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, memo is a dictionary that stores previously computed Fibonacci numbers. Before computing a new Fibonacci number, we first check if it's already in memo. If it is, we simply return the stored value. If it isn't, we compute it, store it in memo, and then return it.\n",
        "\n",
        "This is a top-down approach to dynamic programming, also known as memoization. The original problem is broken down into subproblems (hence \"top-down\"), and the results of these subproblems are cached (or \"memoized\") for later use.\n",
        "\n",
        "This approach ensures that each subproblem is solved only once, rather than multiple times as in the naive recursive approach. As a result, the time complexity of the function is reduced to O(n) from the original exponential time complexity. This makes the function much more efficient for large inputs.\n",
        "\n",
        "However, it's worth noting that the function can still result in a stack overflow for very large inputs due to the recursive calls. For such cases, a bottom-up approach, like the one shown in the previous example, might be more suitable. In the bottom-up approach, we iteratively build up the solution to the problem starting from the base cases and using these to solve larger subproblems.\n",
        "\n",
        "Here's an example of how you might implement a dynamic programming solution to the Fibonacci sequence:"
      ],
      "metadata": {
        "id": "HcUJQjGIvvOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(n):\n",
        "    dp = [0, 1] + [0] * (n - 1)\n",
        "    for i in range(2, n + 1):\n",
        "        dp[i] = dp[i-1] + dp[i-2]\n",
        "    return dp[n]\n"
      ],
      "metadata": {
        "id": "vJnsOt6Is-G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this function, dp is a list that stores the Fibonacci numbers we've already computed, so we never compute a Fibonacci number more than once. This makes the function much more efficient for large values of n.\n",
        "\n",
        "The term \"careful brute force\" comes from the fact that a dynamic programming approach tries out all possible solutions to the subproblems and saves these results. This is different from brute force in the sense that we are not blindly trying all possible solutions, but reusing the solutions to smaller subproblems to solve bigger problems, hence the \"careful\" brute force.\n",
        "\n",
        "The key to the success of dynamic programming lies in identifying the structure of overlapping subproblems and the possibility of reusing the solutions. This can take a lot of careful thought and practice, which is why dynamic programming problems are considered some of the most challenging in the field of computer science."
      ],
      "metadata": {
        "id": "0YtH29A7tA5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dynamic Programming Conclusion\n",
        "dynamic programming can be viewed as a combination of recursion and memoization. It's a powerful technique that allows us to solve complex problems efficiently by breaking them down into simpler subproblems, solving each subproblem only once, and remembering (or \"memoizing\") the results of these subproblems to avoid duplicate work.\n",
        "\n",
        "We typically represent the time complexity of a dynamic programming solution as the product of the number of subproblems and the time we spend per subproblem.\n",
        "\n",
        "For the Fibonacci problem we've been discussing, the number of unique subproblems is n (since we need to compute each Fibonacci number from 1 to n). The time we spend per subproblem is constant (denoted by Θ(1)) because we are merely performing an addition operation for each subproblem, assuming that we've already solved the smaller subproblems.\n",
        "\n",
        "Therefore, the overall time complexity of the dynamic programming solution is n * Θ(1), which simplifies to O(n). This represents a significant improvement over the naive recursive solution, which has exponential time complexity.\n",
        "\n",
        "Here's the bottom-up version of the Fibonacci algorithm, written in Python:"
      ],
      "metadata": {
        "id": "yZypsbcB8U4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BOTTOM-UP APPROACH\n",
        "* exactly same computation\n",
        "* topological sort of subproblem dependency DAG \n",
        "<img src='https://i.imgur.com/XSfd8hf.png'>\n",
        "* can often save space\n"
      ],
      "metadata": {
        "id": "kChDCZvr8iXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(n):\n",
        "    fib_values = [0, 1] + [0] * (n - 1)\n",
        "    for k in range(2, n + 1):\n",
        "        fib_values[k] = fib_values[k-1] + fib_values[k-2]\n",
        "    return fib_values[n]\n"
      ],
      "metadata": {
        "id": "BR-aafKf8hQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this algorithm, we're building up the solutions to the subproblems from the bottom up. We start by initializing an array fib_values to store the Fibonacci numbers. We start from the smallest values (0 and 1), and iteratively fill up the rest of the array using the formula for the Fibonacci sequence. By the time we reach fib_values[n], we've solved all the necessary subproblems, and can simply return the value.\n",
        "\n",
        "This bottom-up approach avoids the potential for stack overflow that can occur with the top-down approach for large inputs, because it doesn't use recursion. It also has a space complexity of O(n), because we're storing all the Fibonacci numbers up to n.\n",
        "\n",
        "However, it's worth noting that if we only care about the nth Fibonacci number and not the entire sequence, we can further optimize the space complexity to O(1) by only keeping track of the last two Fibonacci numbers at any point. The time complexity remains O(n)."
      ],
      "metadata": {
        "id": "r7sAUiPh8pbV"
      }
    }
  ]
}
